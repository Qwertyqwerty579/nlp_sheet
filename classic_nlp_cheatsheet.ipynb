{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d155277",
   "metadata": {},
   "source": [
    "# Classic NLP Cheat Sheet (Pre-Transformers)\n",
    "Русский и английский NLP: TF-IDF, SVM, NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf43e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594bce3",
   "metadata": {},
   "source": [
    "## Russian preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize_ru(text):\n",
    "    tokens = [t.text.lower() for t in tokenize(text)]\n",
    "    lemmas = [\n",
    "        morph.parse(tok)[0].normal_form\n",
    "        for tok in tokens\n",
    "        if tok.isalpha()\n",
    "    ]\n",
    "    return \" \".join(lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b468aa",
   "metadata": {},
   "source": [
    "## TF-IDF setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n",
    "\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=5,\n",
    "    max_df=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c99694",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"tfidf\", char_tfidf),\n",
    "    (\"clf\", LinearSVC(C=0.1, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    (\"tfidf\", word_tfidf),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "nb_pipeline = Pipeline([\n",
    "    (\"tf\", CountVectorizer(ngram_range=(1,2), min_df=5)),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc55ccf",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# svm_pipeline.fit(X_train, y_train)\n",
    "# y_pred = svm_pipeline.predict(X_test)\n",
    "# print(f1_score(y_test, y_pred, average='macro'))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}